# Environment variables for big data platform

# Airflow Configuration
AIRFLOW_UID=50000
AIRFLOW_GID=0
AIRFLOW__CORE__FERNET_KEY=your-fernet-key-here
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
AIRFLOW__CORE__LOAD_EXAMPLES=false

# Database Configuration
MYSQL_ROOT_PASSWORD=rootpass
MYSQL_DATABASE=source_db
MYSQL_USER=etl_user
MYSQL_PASSWORD=etl_pass

POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow

# Hive Configuration
HIVE_METASTORE_USER=hive
HIVE_METASTORE_PASSWORD=hive

# Spark Configuration
SPARK_MASTER_HOST=spark-master
SPARK_MASTER_PORT=7077

# HDFS Configuration
HDFS_NAMENODE_HOST=namenode
HDFS_NAMENODE_PORT=9000

# Port Configuration - Modify these if ports are already in use
AIRFLOW_WEBSERVER_PORT=8080
SPARK_UI_PORT=8081
HDFS_UI_PORT=9870
MYSQL_PORT=3306
HIVE_METASTORE_PORT=9083
SPARK_MASTER_PORT=7077
HDFS_NAMENODE_PORT=9000
REDIS_PORT=6379

# Alternative ports if defaults are occupied
# AIRFLOW_WEBSERVER_PORT=8090
# SPARK_UI_PORT=8091
# HDFS_UI_PORT=9880
# MYSQL_PORT=3307

# Resource Limits
SPARK_EXECUTOR_MEMORY=1g
SPARK_DRIVER_MEMORY=512m
MYSQL_INNODB_BUFFER_POOL_SIZE=1G

# Additional PIP packages
_PIP_ADDITIONAL_REQUIREMENTS=apache-airflow-providers-apache-spark apache-airflow-providers-mysql mysql-connector-python