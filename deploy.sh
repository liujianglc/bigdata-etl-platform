#!/bin/bash

set -e  # Exit on any error

echo "ğŸš€ å¤§æ•°æ®å¹³å°éƒ¨ç½²è„šæœ¬ v2.0"
echo "================================"

# Color codes for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to print colored output
print_status() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
}

print_error() {
    echo -e "${RED}âŒ $1${NC}"
}

print_info() {
    echo -e "${BLUE}â„¹ï¸  $1${NC}"
}

# Check prerequisites
check_prerequisites() {
    print_info "æ£€æŸ¥ç³»ç»Ÿè¦æ±‚..."
    
    # Check Docker
    if ! command -v docker &> /dev/null; then
        print_error "Dockeræœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Docker"
        exit 1
    fi
    
    # Check Docker Compose
    if docker compose version &> /dev/null; then
        DOCKER_COMPOSE_CMD="docker compose"
    elif command -v docker-compose &> /dev/null; then
        DOCKER_COMPOSE_CMD="docker-compose"
    else
        print_error "Docker Composeæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Docker Compose"
        exit 1
    fi
    
    print_status "Dockerå’ŒDocker Composeæ£€æŸ¥é€šè¿‡"
    
    # Check system resources
    if command -v free &> /dev/null; then
        total_mem=$(free -g | awk '/^Mem:/{print $2}')
        if [ "$total_mem" -lt 8 ]; then
            print_warning "ç³»ç»Ÿå†…å­˜å°‘äº8GBï¼Œå¯èƒ½å½±å“æ€§èƒ½"
        fi
    fi
    
    # Check disk space
    available_space=$(df -BG . | awk 'NR==2{print $4}' | sed 's/G//')
    if [ "$available_space" -lt 20 ]; then
        print_warning "å¯ç”¨ç£ç›˜ç©ºé—´å°‘äº20GBï¼Œå¯èƒ½ä¸è¶³"
    fi
}

# Setup environment
setup_environment() {
    print_info "è®¾ç½®ç¯å¢ƒ..."
    
    # Create necessary directories
    mkdir -p logs config plugins dags spark_jobs sample_data
    
    # Set permissions
    chmod -R 755 logs config plugins dags spark_jobs
    chmod -R 777 logs  # Airflow logs need special permissions
    
    # Create .env file if it doesn't exist
    if [ ! -f ".env" ]; then
        cp .env.example .env
        print_status "åˆ›å»ºäº†.envé…ç½®æ–‡ä»¶ï¼Œè¯·æ ¹æ®éœ€è¦ä¿®æ”¹"
    fi
    
    print_status "ç¯å¢ƒè®¾ç½®å®Œæˆ"
}

# Build custom Airflow image
build_custom_image() {
    print_info "æ„å»ºè‡ªå®šä¹‰Airflowé•œåƒ..."
    
    if [ -f "Dockerfile.airflow" ] && [ -f "requirements.txt" ]; then
        # Try building the custom image
        ./build-airflow-image.sh
        if [ $? -eq 0 ]; then
            print_status "è‡ªå®šä¹‰Airflowé•œåƒæ„å»ºæˆåŠŸ"
            export USE_CUSTOM_IMAGE=true
        else
            print_warning "è‡ªå®šä¹‰é•œåƒæ„å»ºå¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹é•œåƒå’Œè¿è¡Œæ—¶å®‰è£…"
            export USE_CUSTOM_IMAGE=false
        fi
    else
        print_warning "æœªæ‰¾åˆ°Dockerfile.airflowæˆ–requirements.txtï¼Œä½¿ç”¨åŸå§‹é•œåƒ"
        export USE_CUSTOM_IMAGE=false
    fi
}

# Deploy services
deploy_services() {
    local mode=$1
    local compose_files="docker-compose.yml"
    
    # Add fallback if custom image build failed
    if [ "$USE_CUSTOM_IMAGE" = "false" ]; then
        if [ -f "docker-compose.fallback.yml" ]; then
            compose_files="$compose_files -f docker-compose.fallback.yml"
            print_info "ä½¿ç”¨åŸå§‹é•œåƒå’Œè¿è¡Œæ—¶å®‰è£…æ¨¡å¼"
        fi
    fi
    
    case $mode in
        "dev"|"development")
            print_info "å¯åŠ¨å¼€å‘ç¯å¢ƒ..."
            if [ -f "docker-compose.override.yml" ]; then
                compose_files="$compose_files -f docker-compose.override.yml"
            fi
            ;;
        "prod"|"production")
            print_info "å¯åŠ¨ç”Ÿäº§ç¯å¢ƒ..."
            if [ -f "docker-compose.prod.yml" ]; then
                compose_files="$compose_files -f docker-compose.prod.yml"
            fi
            ;;
        *)
            print_info "å¯åŠ¨é»˜è®¤ç¯å¢ƒ..."
            ;;
    esac
    
    print_info "ä½¿ç”¨é…ç½®æ–‡ä»¶: $compose_files"
    
    # Start services
    $DOCKER_COMPOSE_CMD $compose_files up -d
    
    if [ $? -eq 0 ]; then
        print_status "æœåŠ¡å¯åŠ¨æˆåŠŸ"
    else
        print_error "æœåŠ¡å¯åŠ¨å¤±è´¥"
        exit 1
    fi
}

# Wait for services to be ready
wait_for_services() {
    print_info "ç­‰å¾…æœåŠ¡å¯åŠ¨å®Œæˆ..."
    
    # Wait for key services
    local max_attempts=30
    local attempt=0
    
    while [ $attempt -lt $max_attempts ]; do
        if $DOCKER_COMPOSE_CMD ps | grep -q "Up.*healthy"; then
            print_status "æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡"
            break
        fi
        
        attempt=$((attempt + 1))
        echo "ç­‰å¾…æœåŠ¡å¯åŠ¨... ($attempt/$max_attempts)"
        sleep 10
    done
    
    if [ $attempt -eq $max_attempts ]; then
        print_warning "æœåŠ¡å¯åŠ¨è¶…æ—¶ï¼Œä½†ç»§ç»­éªŒè¯"
    fi
}

# Verify deployment
verify_deployment() {
    print_info "éªŒè¯éƒ¨ç½²çŠ¶æ€..."
    
    # Check container status
    echo "Dockerå®¹å™¨çŠ¶æ€ï¼š"
    $DOCKER_COMPOSE_CMD ps
    
    # Check web interfaces
    local all_good=true
    
    # Check Airflow
    if curl -s -f http://localhost:8080/health > /dev/null 2>&1; then
        print_status "Airflow Web UI: http://localhost:8080"
    else
        print_error "Airflow Web UIä¸å¯è®¿é—®"
        all_good=false
    fi
    
    # Check Spark (if running)
    if $DOCKER_COMPOSE_CMD ps spark-master | grep -q "Up"; then
        if curl -s -f http://localhost:8081 > /dev/null 2>&1; then
            print_status "Spark Master UI: http://localhost:8081"
        else
            print_warning "Spark Master UIä¸å¯è®¿é—®"
        fi
    fi
    
    # Check HDFS (if running)
    if $DOCKER_COMPOSE_CMD ps namenode | grep -q "Up"; then
        if curl -s -f http://localhost:9870 > /dev/null 2>&1; then
            print_status "HDFS NameNode UI: http://localhost:9870"
        else
            print_warning "HDFS NameNode UIä¸å¯è®¿é—®"
        fi
    fi
    
    if [ "$all_good" = true ]; then
        print_status "æ‰€æœ‰æ ¸å¿ƒæœåŠ¡éªŒè¯é€šè¿‡ï¼"
    else
        print_warning "éƒ¨åˆ†æœåŠ¡å¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´å¯åŠ¨"
    fi
}

# Show deployment summary
show_summary() {
    echo ""
    echo "ğŸ‰ éƒ¨ç½²å®Œæˆï¼"
    echo "================================"
    echo ""
    echo "ğŸ“Š è®¿é—®åœ°å€ï¼š"
    echo "  - Airflow Web UI: http://localhost:8080 (admin/admin)"
    echo "  - Spark Master UI: http://localhost:8081"
    echo "  - HDFS NameNode UI: http://localhost:9870"
    echo "  - MySQL: localhost:3306"
    echo ""
    echo "ğŸ”§ ç®¡ç†å‘½ä»¤ï¼š"
    echo "  - æŸ¥çœ‹æ—¥å¿—: $DOCKER_COMPOSE_CMD logs [service-name]"
    echo "  - é‡å¯æœåŠ¡: $DOCKER_COMPOSE_CMD restart [service-name]"
    echo "  - åœæ­¢æ‰€æœ‰æœåŠ¡: $DOCKER_COMPOSE_CMD down"
    echo "  - å®Œå…¨æ¸…ç†: $DOCKER_COMPOSE_CMD down -v"
    echo ""
    echo "ğŸ“– æ›´å¤šä¿¡æ¯è¯·æŸ¥çœ‹ README.md"
}

# Main deployment logic
main() {
    # Parse command line arguments
    local mode="dev"
    local skip_build=false
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            --mode|-m)
                mode="$2"
                shift 2
                ;;
            --skip-build)
                skip_build=true
                shift
                ;;
            --help|-h)
                echo "ç”¨æ³•: $0 [é€‰é¡¹]"
                echo "é€‰é¡¹:"
                echo "  --mode, -m MODE    éƒ¨ç½²æ¨¡å¼ (dev|prod) [é»˜è®¤: dev]"
                echo "  --skip-build       è·³è¿‡é•œåƒæ„å»º"
                echo "  --help, -h         æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"
                exit 0
                ;;
            *)
                print_error "æœªçŸ¥é€‰é¡¹: $1"
                exit 1
                ;;
        esac
    done
    
    # Execute deployment steps
    check_prerequisites
    setup_environment
    
    if [ "$skip_build" = false ]; then
        build_custom_image
    fi
    
    deploy_services "$mode"
    wait_for_services
    verify_deployment
    show_summary
}

# Run main function with all arguments
main "$@"