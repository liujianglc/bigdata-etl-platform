# å¤§æ•°æ®ETLå¹³å°

åŸºäºDockerçš„å®Œæ•´å¤§æ•°æ®å¤„ç†å¹³å°ï¼ŒåŒ…å«Airflowã€Sparkã€HDFSã€Hiveã€MySQLç­‰ç»„ä»¶ã€‚

## ğŸ—ï¸ æ¶æ„ç»„ä»¶

- **Apache Airflow** - å·¥ä½œæµè°ƒåº¦å’Œç›‘æ§
- **Apache Spark** - åˆ†å¸ƒå¼æ•°æ®å¤„ç†
- **HDFS** - åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ
- **Apache Hive** - æ•°æ®ä»“åº“
- **MySQL** - æºæ•°æ®åº“
- **PostgreSQL** - Airflowå…ƒæ•°æ®å­˜å‚¨
- **Redis** - Airflowä»»åŠ¡é˜Ÿåˆ—

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚

- Docker & Docker Compose
- è‡³å°‘8GBå†…å­˜
- 20GBå¯ç”¨ç£ç›˜ç©ºé—´

### 2. å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
./start.sh

# æˆ–è€…åˆ†æ­¥å¯åŠ¨ï¼ˆæ¨èï¼‰
./start-basic.sh          # å¯åŠ¨åŸºç¡€æœåŠ¡
./start-hdfs-spark.sh     # å¯åŠ¨å¤§æ•°æ®ç»„ä»¶
```

### 3. è®¿é—®ç•Œé¢

- **Airflow Web UI**: http://localhost:8080 (admin/admin)
- **Spark Master UI**: http://localhost:8081
- **HDFS NameNode UI**: http://localhost:9870
- **MySQL**: localhost:3306 (root/rootpass)

## ğŸ“Š å¯ç”¨çš„DAG

### 1. simple_mysql_etl
- **é€‚ç”¨åœºæ™¯**: å…¥é—¨å­¦ä¹ 
- **åŠŸèƒ½**: åŸºç¡€MySQLæ•°æ®å¤„ç†
- **æ¨è**: åˆå­¦è€…é¦–é€‰

### 2. real_bigdata_pipeline
- **é€‚ç”¨åœºæ™¯**: æ¨¡æ‹Ÿå¤§æ•°æ®æµç¨‹
- **åŠŸèƒ½**: å®Œæ•´ETLæµç¨‹æ¼”ç¤º
- **ç‰¹ç‚¹**: æ¨¡æ‹ŸHDFSå’ŒHiveæ“ä½œ

### 3. production_bigdata_pipeline
- **é€‚ç”¨åœºæ™¯**: ç”Ÿäº§ç¯å¢ƒ
- **åŠŸèƒ½**: çœŸå®å¤§æ•°æ®ETL
- **ç‰¹ç‚¹**: çœŸå®å†™å…¥HDFSå’ŒHive

### 4. complete_bigdata_etl
- **é€‚ç”¨åœºæ™¯**: å®Œæ•´æ¼”ç¤º
- **åŠŸèƒ½**: ç«¯åˆ°ç«¯å¤§æ•°æ®å¤„ç†
- **ç‰¹ç‚¹**: åŒ…å«æ‰€æœ‰ç»„ä»¶

## ğŸ”§ é…ç½®æ–‡ä»¶

### æ ¸å¿ƒé…ç½®
- `docker-compose.yaml` - ä¸»è¦æœåŠ¡é…ç½®
- `hive-site.xml` - Hiveé…ç½®
- `spark-defaults.conf.txt` - Sparké…ç½®
- `init-mysql-data.sql` - MySQLåˆå§‹æ•°æ®

### å¯åŠ¨è„šæœ¬
- `start.sh` - å®Œæ•´ç¯å¢ƒå¯åŠ¨
- `start-basic.sh` - åŸºç¡€æœåŠ¡å¯åŠ¨
- `start-hdfs-spark.sh` - å¤§æ•°æ®ç»„ä»¶å¯åŠ¨

## ğŸ“ ç›®å½•ç»“æ„

```
â”œâ”€â”€ dags/                    # Airflow DAGæ–‡ä»¶
â”œâ”€â”€ spark_jobs/              # Sparkä½œä¸šè„šæœ¬
â”œâ”€â”€ hadoop-config/           # Hadoopé…ç½®æ–‡ä»¶
â”œâ”€â”€ docker-compose.yaml      # DockeræœåŠ¡é…ç½®
â”œâ”€â”€ hive-site.xml           # Hiveé…ç½®
â”œâ”€â”€ init-mysql-data.sql     # MySQLåˆå§‹æ•°æ®
â””â”€â”€ start.sh                # å¯åŠ¨è„šæœ¬
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æœåŠ¡å¯åŠ¨å¤±è´¥**
   ```bash
   ./troubleshoot.sh
   ```

2. **DAGä¸æ˜¾ç¤º**
   ```bash
   ./check-dag-syntax.sh
   ```

3. **HDFSæ•°æ®æ£€æŸ¥**
   ```bash
   ./check-hdfs-real.sh
   ```

### é‡å¯æœåŠ¡
```bash
# å®Œå…¨é‡å¯
docker-compose down
./start.sh

# é‡å¯ç‰¹å®šæœåŠ¡
docker-compose restart airflow-scheduler
```

## ğŸ“ˆ æ•°æ®æµç¨‹

```
MySQL â†’ CSV â†’ HDFS â†’ Hive â†’ åˆ†ææŠ¥å‘Š
```

1. **æ•°æ®æå–**: ä»MySQLæå–ä¸šåŠ¡æ•°æ®
2. **æ•°æ®å­˜å‚¨**: å†™å…¥HDFSåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ
3. **æ•°æ®å»ºæ¨¡**: åœ¨Hiveä¸­åˆ›å»ºæ•°æ®ä»“åº“è¡¨
4. **æ•°æ®åˆ†æ**: æ‰§è¡Œä¸šåŠ¡åˆ†ææŸ¥è¯¢
5. **æŠ¥å‘Šç”Ÿæˆ**: ç”Ÿæˆè¯¦ç»†çš„æ‰§è¡ŒæŠ¥å‘Š

## ğŸ” ç›‘æ§å’Œæ—¥å¿—

- **Airflowæ—¥å¿—**: `./logs/` ç›®å½•
- **æœåŠ¡æ—¥å¿—**: `docker-compose logs [service-name]`
- **HDFSçŠ¶æ€**: http://localhost:9870
- **Sparkä½œä¸š**: http://localhost:8081

## ğŸ“ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„DAG
1. åœ¨ `dags/` ç›®å½•åˆ›å»ºPythonæ–‡ä»¶
2. ä½¿ç”¨ç°æœ‰DAGä½œä¸ºæ¨¡æ¿
3. æµ‹è¯•è¯­æ³•: `python -m py_compile dags/your_dag.py`

### æ·»åŠ æ–°çš„Sparkä½œä¸š
1. åœ¨ `spark_jobs/` ç›®å½•åˆ›å»ºPythonæ–‡ä»¶
2. åœ¨DAGä¸­å¼•ç”¨ä½œä¸šè·¯å¾„
3. ç¡®ä¿ä½œä¸šå¯ä»¥è®¿é—®å¿…è¦çš„ä¾èµ–

## ğŸ¤ è´¡çŒ®

1. Forké¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. åˆ›å»ºPull Request

## ğŸ“„ è®¸å¯è¯

MIT License